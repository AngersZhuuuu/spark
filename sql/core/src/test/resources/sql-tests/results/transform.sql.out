-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 10


-- !query
CREATE OR REPLACE TEMPORARY VIEW t1 AS SELECT * FROM VALUES
('1', true, unhex('537061726B2053514C'), tinyint(1), 1, smallint(100), bigint(1), float(1.0), 1.0, Decimal(1.0), timestamp('1997-01-02'), date('2000-04-01')),
('2', false, unhex('537061726B2053514C'), tinyint(2), 2,  smallint(200), bigint(2), float(2.0), 2.0, Decimal(2.0), timestamp('1997-01-02 03:04:05'), date('2000-04-02')),
('3', true, unhex('537061726B2053514C'), tinyint(3), 3, smallint(300), bigint(3), float(3.0), 3.0, Decimal(3.0), timestamp('1997-02-10 17:32:01-08'), date('2000-04-03'))
as t1(a, b, c, d, e, f, g, h, i, j, k, l)
-- !query schema
struct<>
-- !query output



-- !query
SELECT TRANSFORM(a)
USING 'cat' AS (a)
FROM t1
-- !query schema
struct<a:string>
-- !query output
1
2
3


-- !query
SELECT TRANSFORM(a)
USING 'some_non_existent_command' AS (a)
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkException
Subprocess exited with status 127. Error: /bin/bash: some_non_existent_command: command not found


-- !query
SELECT TRANSFORM(a)
USING 'python some_non_existent_file' AS (a)
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkException
Subprocess exited with status 2. Error: python: can't open file 'some_non_existent_file': [Errno 2] No such file or directory


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
    SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
    USING 'cat' AS (
        a string,
        b boolean,
        c binary,
        d tinyint,
        e int,
        f smallint,
        g long,
        h float,
        i double,
        j decimal(38, 18),
        k timestamp,
        l date)
    FROM t1
) tmp
-- !query schema
struct<a:string,b:boolean,decode(c, UTF-8):string,d:tinyint,e:int,f:smallint,g:bigint,h:float,i:double,j:decimal(38,18),k:timestamp,l:date>
-- !query output
1	true	Spark SQL	1	1	100	1	1.0	1.0	1.000000000000000000	1997-01-02 00:00:00	2000-04-01
2	false	Spark SQL	2	2	200	2	2.0	2.0	2.000000000000000000	1997-01-02 03:04:05	2000-04-02
3	true	Spark SQL	3	3	300	3	3.0	3.0	3.000000000000000000	1997-02-10 17:32:01	2000-04-03


-- !query
SELECT TRANSFORM(a, b)
USING 'cat'
FROM t1
-- !query schema
struct<key:string,value:string>
-- !query output
1	true
2	false
3	true


-- !query
SELECT TRANSFORM(a, b, c, d, e, f, g, h, i)
USING 'cat' as (a int, b short, c long, d byte, e float, f double, g decimal(38, 18), h date, i timestamp)
FROM VALUES
('a','','1231a','a','213.21a','213.21a','0a.21d','2000-04-01123','1997-0102 00:00:') tmp(a, b, c, d, e, f, g, h, i)
-- !query schema
struct<a:int,b:smallint,c:bigint,d:tinyint,e:float,f:double,g:decimal(38,18),h:date,i:timestamp>
-- !query output
NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL


-- !query
SELECT TRANSFORM(b, max(a), sum(f))
USING 'cat' AS (a, b)
FROM t1
GROUP BY b
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

mismatched input 'GROUP' expecting {<EOF>, ';'}(line 4, pos 0)

== SQL ==
SELECT TRANSFORM(b, max(a), sum(f))
USING 'cat' AS (a, b)
FROM t1
GROUP BY b
^^^


-- !query
MAP a, b USING 'cat' AS (a, b) FROM t1
-- !query schema
struct<a:string,b:string>
-- !query output
1	true
2	false
3	true


-- !query
REDUCE a, b USING 'cat' AS (a, b) FROM t1
-- !query schema
struct<a:string,b:string>
-- !query output
1	true
2	false
3	true
